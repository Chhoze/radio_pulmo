{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle de segmentation\n",
    "## Chris HOZE - Nov 2024\n",
    "\n",
    "Inspiré depuis pour le modèle\n",
    "\n",
    "https://www.kaggle.com/code/nikhilpandey360/lung-segmentation-from-chest-x-ray-dataset \n",
    "\n",
    "Et pour les métriques\n",
    "\n",
    "https://www.kaggle.com/code/sajeelhashmi/image-segmentation#Get-Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "#from tqdm import tqdm\n",
    "import os\n",
    "from cv2 import imread, createCLAHE \n",
    "import cv2\n",
    "from glob import glob\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "path_to_data = r\"C:\\Users\\Inrae\\Documents\\Projet_Data_Science\"\n",
    "data_folder_path = os.path.join(path_to_data,\"COVID-19_Radiography_Dataset\")\n",
    "\n",
    "dim=256\n",
    "size_max_cat = 3000 # None if we want the whole dataset\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise image and mask \n",
    "def plotMask(X,y):\n",
    "    sample = []\n",
    "    \n",
    "    for i in range(6):\n",
    "        left = X[i]\n",
    "        right = y[i]\n",
    "        combined = np.hstack((left,right))\n",
    "        sample.append(combined)\n",
    "        \n",
    "        \n",
    "    for i in range(0,6,3):\n",
    "\n",
    "        plt.figure(figsize=(25,10))\n",
    "        \n",
    "        plt.subplot(2,3,1+i)\n",
    "        plt.imshow(sample[i])\n",
    "        \n",
    "        plt.subplot(2,3,2+i)\n",
    "        plt.imshow(sample[i+1])\n",
    "        \n",
    "        \n",
    "        plt.subplot(2,3,3+i)\n",
    "        plt.imshow(sample[i+2])\n",
    "        \n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def getData(X_shape, N = None):\n",
    "    im_array = []\n",
    "    mask_array = []\n",
    "\n",
    "    for cat in [\"Normal\", \"Lung_Opacity\", \"Viral_Pneumonia\", \"COVID\"]:       \n",
    "        image_path = os.path.join(data_folder_path,cat,\"images\")\n",
    "        mask_path = os.path.join(data_folder_path,cat,\"masks\")\n",
    "        files = os.listdir(image_path)\n",
    "        random.Random(1337).shuffle(files)\n",
    "        \n",
    "        if (N is None):\n",
    "            N = len(files)\n",
    "        else:\n",
    "            N = min(N, len(files))\n",
    "        for i in files[:N]: \n",
    "            im = cv2.resize(cv2.imread(os.path.join(image_path,i)),(X_shape,X_shape))[:,:,0]\n",
    "            mask = cv2.resize(cv2.imread(os.path.join(mask_path,i)),(X_shape,X_shape))[:,:,0]  \n",
    "            im_array.append(im)\n",
    "            mask_array.append(mask)\n",
    "    \n",
    "    images = np.array(im_array).reshape(len(im_array),dim,dim,1)\n",
    "    masks = np.array(mask_array).reshape(len(mask_array),dim,dim,1)\n",
    "    return images, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data\n",
    "dim = 256\n",
    "images, masks = getData(dim,N=size_max_cat)\n",
    "\n",
    "print(\"visualize dataset\")\n",
    "plotMask(images, masks)\n",
    "\n",
    "\n",
    "print(\"dataset size : images\", images.shape, \"masks\", masks.shape)\n",
    "\n",
    "\n",
    "print(\"Shape de image_scaled: \", images.shape, \"type de image_scaled: \", images.dtype)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras import backend as keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "\n",
    "def unet(input_size=(dim,dim,1)):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[conv10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n",
    "weight_path=\"{}_segmentation.best.keras\".format('cxr_reg')\n",
    "\n",
    "checkpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n",
    "                             save_best_only=True, mode='min') #save_weights_only = True)\n",
    "\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.5, \n",
    "                                   patience=3, \n",
    "                                   verbose=1, mode='min', min_delta=0.001, cooldown=2, min_lr=1e-6)\n",
    "early = EarlyStopping(monitor=\"val_loss\", \n",
    "                      mode=\"min\",\n",
    "                      min_delta=0.0001,\n",
    "                      patience=5)\n",
    "callbacks_list = [checkpoint, early, reduceLROnPlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = unet(input_size=(256,256,1))\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"Dice\",\n",
    "                  metrics=['BinaryIoU','binary_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_vol, valid_vol, train_seg, valid_seg = train_test_split((images-127)/127, \n",
    "                                                             (masks>127).astype(np.float32),\n",
    "                                                             test_size = 0.1,random_state = 2018)\n",
    "\n",
    "train_vol, test_vol, train_seg, test_seg = train_test_split(train_vol,train_seg, \n",
    "                                                            test_size = 0.1, \n",
    "                                                            random_state = 2018)\n",
    "\n",
    "datagen = ImageDataGenerator() \n",
    "\n",
    "# Augmenter respectivement les jeu de données d'entrainement\n",
    "train_dataset = datagen.flow(train_vol, train_seg, batch_size = batch_size)\n",
    "\n",
    "test_dataset = datagen.flow(test_vol, test_seg, batch_size = batch_size)\n",
    "\n",
    "val_dataset = datagen.flow(valid_vol, valid_seg, batch_size = batch_size)\n",
    "\n",
    "\n",
    "print(\"Shape de train_scaled: \", train_vol.shape, \"type de train_scaled: \", train_vol.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir un batch d'images\n",
    "dataiter = iter(train_dataset)\n",
    "image, mask = next(dataiter)\n",
    "plotMask(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del loss_history\n",
    "import gc\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "loss_history = model.fit(train_dataset,\n",
    "                         batch_size = batch_size,\n",
    "                  epochs = 3,\n",
    "                  validation_data = test_dataset,\n",
    "                  callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
    "ax1.plot(loss_history.history['loss'], '-', label = 'Loss')\n",
    "ax1.plot(loss_history.history['val_loss'], '-', label = 'Validation Loss')\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(100*np.array(loss_history.history['binary_accuracy']), '-', \n",
    "         label = 'Accuracy')\n",
    "ax2.plot(100*np.array(loss_history.history['val_binary_accuracy']), '-',\n",
    "         label = 'Validation Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si on en reentraine pas le modele on peut l'importer\n",
    "#model_seg  = tf.keras.models.load_model(\"cxr_reg_segmentation.best.keras\")\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "     intersection = np.sum(y_true * y_pred)\n",
    "     return (2. * intersection) / (np.sum(y_true) + np.sum(y_pred))\n",
    "\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coefficient(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def test_accuracy(model, X, y):\n",
    "    X_test, y_test = X, y\n",
    "    batch_size = 8\n",
    "    predictions = model.predict(X_test, batch_size=batch_size)\n",
    "    \n",
    "    # Reshape predictions if necessary (assuming single-channel masks)\n",
    "    y_pred = np.squeeze(predictions)\n",
    "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
    "\n",
    "    threshold = 0.5\n",
    "    y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "    # Calculate pixel-wise accuracy\n",
    "    accuracy = np.mean(y_pred_binary == y_test)\n",
    "\n",
    "    dice_coefficient_score = dice_coefficient(y_test,predictions)\n",
    "    dice_loss_score = dice_loss(y_test,predictions)\n",
    "    print(f'Dice Coefficient: {dice_coefficient_score:.4f}')\n",
    "    print(f'Dice Loss: {dice_loss_score:.4f}')\n",
    "    print(f'Pixel accuracy: {accuracy:.4f}')\n",
    "\n",
    "print(\"jeu de données d'entrainement\")\n",
    "test_accuracy(model_seg, train_vol[:1000], train_seg[:1000])\n",
    "\n",
    "print(\"jeu de données de paramétrage\")\n",
    "test_accuracy(model_seg, test_vol, test_seg)\n",
    "\n",
    "print(\"jeu de données de validation\")\n",
    "test_accuracy(model_seg, valid_vol, valid_seg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir un batch d'images\n",
    "dataiter = iter(val_dataset)\n",
    "image, mask = next(dataiter)\n",
    "\n",
    "preds = model_seg.predict(image)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "for i in range(0,9,3):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(image[i])\n",
    "    plt.xlabel(\"Base Image\")\n",
    "    \n",
    "    \n",
    "    plt.subplot(3,3,i+2)\n",
    "    plt.imshow(mask[i])\n",
    "    plt.xlabel(\"Mask\")\n",
    "    \n",
    "    plt.subplot(3,3,i+3)\n",
    "    plt.imshow(preds[i])\n",
    "    plt.xlabel(\"Prediction\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RadioPulmonaire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
