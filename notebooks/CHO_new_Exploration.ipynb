{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pickle\n",
    "\n",
    "import os \n",
    "import pathlib\n",
    "\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib as plt\n",
    "\n",
    "# Insérez votre code ici\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "path_to_data = r\"C:\\Users\\Inrae\\Documents\\Projet_Data_Science\"\n",
    "data_folder_path = os.path.join(path_to_data,\"COVID-19_Radiography_Dataset\")\n",
    "output_path = os.path.join(path_to_data,\"processed\")\n",
    "size=(256, 256)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Charger les données d'images\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    output_path,\n",
    "    image_size = size,  # Redimensionner les imags\n",
    "    batch_size = 32,\n",
    "    label_mode = None,\n",
    "    color_mode = \"grayscale\",\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "# Récupérer les noms des fichiers dans le dataset\n",
    "#file_paths = [os.path.join(output_path, fname) for fname in dataset.file_paths]\n",
    "\n",
    "# Charger les metadonnees\n",
    "glob_add_info_df = pd.DataFrame()\n",
    "\n",
    "for classes in ['COVID','Lung_Opacity','Normal','Viral_Pneumonia']:\n",
    "    # Charger le fichier CSV\n",
    "    filename=classes+\".metadata.xlsx\"\n",
    "    file_path = os.path.join(output_path,filename)\n",
    "    additional_info_df = pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "    # On cree une colonne correspondant aux labels\n",
    "    additional_info_df['LABELS'] = classes\n",
    "   \n",
    "    # Dans les noms de fichiers, On remplace les Viral Pneumonia par Viral_Pneumonia et NORMAL par Normal\n",
    "    #additional_info_df['FILE NAME'] = additional_info_df['FILE NAME'].str.replace('Viral Pneumonia', 'Viral_Pneumonia')\n",
    "    additional_info_df['FILE NAME'] = additional_info_df['FILE NAME'].str.replace('NORMAL', 'Normal')\n",
    "\n",
    "    class_path = os.path.join(output_path,classes)\n",
    "    additional_info_df['FILE NAME'] = class_path + \"\\\\\" + additional_info_df['FILE NAME'] + \".png_masked.png\"\n",
    "    \n",
    "    # On recode les URL\n",
    "    additional_info_df.replace({\n",
    "    \"https://www.kaggle.com/c/rsna-pneumonia-detection-challenge/data\" : \"rnsa\",\n",
    "    \"https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia\" : \"pneumonia-chestxray\",                     \n",
    "    \"https://bimcv.cipf.es/bimcv-projects/bimcv-covid19/#1590858128006-9e640421-6711\"  : \"bimcv\",\n",
    "    \"https://github.com/armiro/COVID-CXNet\" : \"CXNet\",\n",
    "    \"https://eurorad.org\" : \"eurorad\",                                                            \n",
    "    \"https://github.com/ml-workgroup/covid-19-image-repository/tree/master/png\"  : \"ml-workgroup\",\n",
    "    \"https://github.com/ieee8023/covid-chestxray-dataset\" : \"covid-chestxray\",\n",
    "    \"https://sirm.org/category/senza-categoria/covid-19/\" : \"senza\",\n",
    "    },\n",
    "    inplace = True\n",
    "    )\n",
    "\n",
    "    # On supprime l info size et formal \n",
    "    additional_info_df = additional_info_df.drop([\"FORMAT\", \"SIZE\"], axis = 1)\n",
    "    \n",
    "    # Ajouter les données de cette classe au DataFrame global\n",
    "    glob_add_info_df = pd.concat([glob_add_info_df,additional_info_df], ignore_index=True)\n",
    "\n",
    "\n",
    "glob_add_info_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les images et les aplatir en vecteurs\n",
    "images = []\n",
    "for image_batch in dataset:\n",
    "    image_batch = image_batch.numpy().reshape(image_batch.shape[0], -1)\n",
    "    images.append(image_batch)\n",
    "\n",
    "# Convertir les images en un tableau numpy\n",
    "images = np.vstack(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames =  dataset.file_paths\n",
    "\n",
    "# On verifie que tout est OK dans les noms de fichiers\n",
    "for filename in filenames:\n",
    "    if filename not in glob_add_info_df['FILE NAME'].values:\n",
    "        print(f\"Missing: {filename}\")\n",
    "\n",
    "# On reeordonne selon l ordre des fichiers\n",
    "glob_add_info_df_order = glob_add_info_df.set_index('FILE NAME').loc[filenames].reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On fait les comptages par categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On affiche les images par catégories ou par source avec plotly express\n",
    "px.histogram(glob_add_info_df_order, x=\"LABELS\", color=\"URL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On fait les statistiques exploratoires par categories (label ou source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Créer un DataFrame avec les images et informations supplémentaires\n",
    "df = pd.DataFrame({\n",
    "    'label': glob_add_info_df_order.LABELS,\n",
    "    'source': glob_add_info_df_order.URL,\n",
    "    'image': list(images)  # Chaque image est un vecteur de pixels\n",
    "})\n",
    "\n",
    "# Ajouter une nouvelle colonne 'label_source' qui combine 'label' et 'source'\n",
    "df[\"label_source\"] = df[\"label\"] + \"_\" + df[\"source\"]\n",
    "\n",
    "# Calculer la moyenne et l'écart-type des pixels pour chaque image\n",
    "df['mean_pixel'] = df['image'].apply(lambda x: np.mean(x))\n",
    "df['std_pixel'] = df['image'].apply(lambda x: np.std(x))\n",
    "df['min_pixel'] = df['image'].apply(lambda x: np.min(x))\n",
    "df['max_pixel'] = df['image'].apply(lambda x: np.max(x))\n",
    "df['median_pixel'] = df['image'].apply(lambda x: np.median(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export d'un jeu de données d'exemple avec 5 images par source de donnees\n",
    "\n",
    "df_small = df.groupby('source').apply(lambda x: x.sample(5, random_state=42)).reset_index(drop=True)\n",
    "\n",
    "# On garde les colonnes qui nous interesse\n",
    "df_small = df_small.drop(columns=[\"label_source\", \"mean_pixel\",\"std_pixel\"])\n",
    "\n",
    "# On recrée un nom qui sera utile pour le streamlit\n",
    "\n",
    "df_small['nom'] = df_small.groupby('label').cumcount() + 1\n",
    "df_small['nom'] = df_small['label'] + '_' + df_small['nom'].astype(str)\n",
    "\n",
    "# On exporte\n",
    "display(df_small)\n",
    "\n",
    "path_df_small = os.path.join(path_to_data,\"radio_pulmo\",\"src\",\"streamlit\",\"resources\",\"df_small.pkl\")\n",
    "\n",
    "# Exporter le DataFrame avec les images nettoyées dans un fichier pickle\n",
    "with open(path_df_small, 'wb') as f:\n",
    "    pickle.dump(df_small, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_mean_std(df, cat=\"label\"):\n",
    "# Créer un graphique avec Plotly\n",
    "    fig = px.scatter(\n",
    "        df, \n",
    "        x='mean_pixel',  # Moyenne des pixels\n",
    "        y='std_pixel',   # Ecart-type des pixels\n",
    "        color=cat,  # Couleur selon le label_source\n",
    "        title=\"Moyenne et Ecart-Type des Pixels par \" +  cat,\n",
    "        labels={'mean_pixel': 'Moyenne des Pixels', 'std_pixel': 'Ecart-Type des Pixels'},\n",
    "        #template=\"plotly_dark\"\n",
    "        )  # Utilisation d'un fond sombre\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "def boxplot(df, cat=\"label\"):\n",
    "    # Créer un barplot avec Plotly\n",
    "    fig = px.box(\n",
    "        df, \n",
    "        x=cat,                # Les catégories (sur l'axe des abscisses)\n",
    "        y='mean_pixel',       # La moyenne des pixels (sur l'axe des ordonnées)\n",
    "        color=cat,            # Couleur selon la catégorie (cat)\n",
    "        title=f\"Boxplot des Moyennes des Pixels par {cat}\",\n",
    "        #template=\"plotly_dark\"\n",
    "    )\n",
    "    \n",
    "    # Afficher le graphique\n",
    "    fig.show()\n",
    "\n",
    "display(df.head())\n",
    "boxplot(df, cat=\"source\")\n",
    "\n",
    "plot_mean_std(df, cat=\"label\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On exporte le dataset sans le fichier image\n",
    "\n",
    "df_mean_std = df.drop(columns=['image'])\n",
    "path_df = os.path.join(path_to_data,\"radio_pulmo\",\"src\",\"streamlit\",\"resources\",\"df_mean_std.pkl\")\n",
    "display(df_mean_std.head())\n",
    "\n",
    "print(path_df)\n",
    "df_mean_std.to_pickle(path_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On fait les images moyennes par label_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculer la moyenne de l'image pour chaque catégorie/source\n",
    "average_images = df.groupby(\"label_source\")['image'].apply(lambda x: np.mean(np.vstack(x), axis=0)).reset_index()\n",
    "\n",
    "# Reshape l'image moyenne (si nécessaire pour l'affichage)\n",
    "average_images['image'] = average_images['image'].apply(lambda x: x.reshape(size[0],size[1],1))\n",
    "\n",
    "# Affichage du DataFrame avec les images moyennes\n",
    "average_images.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Affichage des images moyennes par catégorie et source\n",
    "fig, axes = plt.subplots(len(average_images), 1, figsize=(5, 50), )\n",
    "\n",
    "for i, row in enumerate(average_images.itertuples()):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(row.image, cmap=\"gray\")\n",
    "    ax.set_title(row.label_source)\n",
    "    ax.axis('off')  \n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remise en forme des images\n",
    "average_images['image'] = average_images['image'].apply(lambda x: np.squeeze(x))  # Enlève les dimensions inutiles\n",
    "\n",
    "\n",
    "# Verifier le fichier average_image\n",
    "\n",
    "display(average_images)\n",
    "\n",
    "# Vérification de la forme des images\n",
    "print(average_images['image'].iloc[0].shape)  # Affiche la forme d'une image pour vérification\n",
    "\n",
    "path_avg_image = os.path.join(path_to_data,\"radio_pulmo\",\"src\",\"streamlit\",\"resources\",\"df_avg_img.pkl\")\n",
    "\n",
    "# Exporter le DataFrame avec les images nettoyées dans un fichier pickle\n",
    "with open(path_avg_image, 'wb') as f:\n",
    "    pickle.dump(path_avg_image, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On fait une ACP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les images (centrer et réduire)\n",
    "scaler = StandardScaler()\n",
    "images_flattened = np.array([image.flatten() for image in df['image']])\n",
    "images_scaled = scaler.fit_transform(images_flattened) \n",
    "\n",
    "# Appliquer l'ACP sur les images normalisées\n",
    "pca = PCA(n_components=0.95)\n",
    "images_pca = pca.fit_transform(images_scaled)\n",
    "\n",
    "print(\"il faut \",  len(pca.explained_variance_ratio_), \"pour expliquer 95% de la variance initiale\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variance expliquée par les composantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On refait avec 10 composantes uniquement\n",
    "\n",
    "# Appliquer l'ACP sur les images normalisées\n",
    "pca = PCA(n_components=20)\n",
    "images_pca = pca.fit_transform(images_scaled)\n",
    "\n",
    "# Tracer le graph d ecolution de la variance\n",
    "\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "def plot_var(i):\n",
    "    # Vérifier que l'indice i est dans les limites de explained_variance\n",
    "    if i > len(explained_variance):\n",
    "        print(f\"Erreur: i doit être inférieur ou égal à {len(explained_variance)}\")\n",
    "        return\n",
    "    \n",
    "    # Créer un DataFrame pour utiliser avec Plotly\n",
    "    x_values = range(1, i+1)\n",
    "    y_values = explained_variance[:i]\n",
    "    cumulative_values = explained_variance.cumsum()[:i]\n",
    "    \n",
    "    # Créer le graphique avec Plotly Express\n",
    "    fig = px.bar(\n",
    "        x=x_values,\n",
    "        y=cumulative_values,\n",
    "        title=\"Évolution de la variance expliquée par les composantes principales\",\n",
    "        labels={'x': 'Numéro de la composante principale', 'y': 'Variance cumulée'},\n",
    "        text=y_values.round(3)\n",
    "    )\n",
    "\n",
    "    fig.update_traces(texttemplate='%{text:.3f}') \n",
    "    # Afficher le graphique\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple : plot des 20 premieres composantes\n",
    "\n",
    "plot_var(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Représentation des catégories sur les composantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot3d_pca(num_components = [0, 1, 2], supp = \"label\"):\n",
    "    total_var = pca.explained_variance_ratio_[num_components].sum() * 100\n",
    "    supp = df[supp]\n",
    "    cats = supp.unique()\n",
    "\n",
    "    if len(num_components) == 3:\n",
    "        \n",
    "        fig = px.scatter_3d(\n",
    "\n",
    "            images_pca, x = num_components[0], y =  num_components[1], z =  num_components[2], color = supp,\n",
    "            title=f'Total Explained Variance: {total_var:.2f}%',\n",
    "            \n",
    "        )\n",
    "        fig.update_layout(scene=dict(xaxis=dict(backgroundcolor='darkgray', gridcolor='gray', tickcolor='white', title = \"PC_\" +  str(num_components[0])),\n",
    "                yaxis=dict(backgroundcolor='darkgray', gridcolor='gray', tickcolor='white',  title = \"PC_\" +  str(num_components[1])),\n",
    "                zaxis=dict(backgroundcolor='darkgray', gridcolor='gray', tickcolor='white', title = \"PC_\" +  str(num_components[2] ))))\n",
    "        fig.update_traces(marker=dict(size=2))\n",
    "        fig.show()\n",
    "\n",
    "    if len(num_components) == 2:\n",
    "        fig = px.scatter(\n",
    "\n",
    "            images_pca, x = num_components[0], y =  num_components[1], color = supp,\n",
    "            title=f'Total Explained Variance: {total_var:.2f}%',\n",
    "           )\n",
    "        fig.update_layout(scene=dict(xaxis=dict(backgroundcolor='slategray', gridcolor='lightgray', tickcolor='white', title = \"PC_\" +  str(num_components[0])),\n",
    "                yaxis=dict(backgroundcolor='slategray', gridcolor='lightgray', tickcolor='white',  title = \"PC_\" +  str(num_components[1])))) \n",
    "        \n",
    "        fig.update_traces(marker=dict(size=2))\n",
    "        fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On affiche la distribution des images par label et par source selon les composantes\n",
    "#### Par label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot3d_pca([0,1], \"label\")\n",
    "\n",
    "plot3d_pca([2,3], \"label\")\n",
    "\n",
    "plot3d_pca([0,1,2], \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Par source de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot3d_pca([0,1], \"source\")\n",
    "\n",
    "plot3d_pca([2,3], \"source\")\n",
    "\n",
    "plot3d_pca([0,1,2], \"source\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Afficher les images des composantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_mean_image(i=0):\n",
    "    plt.figure()\n",
    "    plt.imshow(pca.components_[i].reshape(size), cmap = 'gray')\n",
    "    plt.axis('off')  # Enlève les axes\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    display_mean_image(i)\n",
    "\n",
    "# Sauvegarder les composants PCA dans un fichier .pkl \n",
    "\n",
    "components = pca.components_\n",
    "\n",
    "path_components = os.path.join(path_to_data,\"radio_pulmo\",\"src\",\"streamlit\",\"resources\",\"pca\", \"pca_components.pkl\")\n",
    "\n",
    "with open(path_components, 'wb') as file:\n",
    "    pickle.dump(components, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On exporte en dataframe les images et leur composantes \n",
    "\n",
    "# On transforme en dataframe\n",
    "pca_df = pd.DataFrame(images_pca)\n",
    "\n",
    "# On ajoute les infos supplémentaires\n",
    "pca_df['label'] = df['label']\n",
    "pca_df['source'] = df['source']\n",
    "pca_df['label_source'] = df['label_source']\n",
    "\n",
    "# On cree l adresse du fichier de sortie\n",
    "\n",
    "path_pca_df = os.path.join(path_to_data,\"radio_pulmo\",\"src\",\"streamlit\",\"resources\",\"pca_df.pkl\")\n",
    "\n",
    "# # On exporte en pickle\n",
    "pca_df.to_pickle(path_pca_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On exporte les composantes de l'ACP et les parts de variances associées\n",
    "\n",
    "# Composantes principales (matrice des vecteurs propres)\n",
    "components = pca.components_\n",
    "\n",
    "# Variance expliquée par chaque composante\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "\n",
    "# On exporte en dataframe les composantes de l'ACP \n",
    "\n",
    "components_df = pd.DataFrame(components, columns=[f\"Pixel_{i}\" for i in range(components.shape[1])])\n",
    "\n",
    "path_components_df = os.path.join(path_to_data,\"radio_pulmo\",\"src\",\"streamlit\",\"resources\",\"pca_components.pkl\")\n",
    "\n",
    "# Exporter les résultats si nécessaire\n",
    "components_df.to_pickle(path_components_df)\n",
    "\n",
    "# Exporter la variance expliquée\n",
    "variance_df = pd.DataFrame({'Component': [f'PC{i+1}' for i in range(len(explained_variance))],\n",
    "                            'Explained Variance': explained_variance})\n",
    "\n",
    "path_variance_df = os.path.join(path_to_data,\"radio_pulmo\",\"src\",\"streamlit\",\"resources\",\"pca_variance.pkl\")\n",
    "\n",
    "# Exporter les résultats si nécessaire\n",
    "variance_df.to_pickle(path_variance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  On exporte les images moyennes des composantes\n",
    "\n",
    "# Calculer les images moyennes pour chaque composante principale\n",
    "mean_images = []\n",
    "for i in range(10):\n",
    "    # Projetons les données sur chaque composante principale\n",
    "    projected_on_component = images_pca[:, i]  # Projection sur la composante i\n",
    "    # Reconstituer l'image moyenne dans l'espace de la composante\n",
    "    mean_image = pca.components_[i] * np.mean(projected_on_component)  # Moyenne des images projetées\n",
    "    mean_images.append(mean_image)\n",
    "\n",
    "# Créer un DataFrame avec les résultats\n",
    "mean_images_df = pd.DataFrame(mean_images, columns=[f'Pixel_{i}' for i in range(images_scaled.shape[1])])\n",
    "\n",
    "# Afficher le DataFrame\n",
    "#print(mean_images_df.head())\n",
    "\n",
    "path_mean_image = os.path.join(path_to_data,\"radio_pulmo\",\"src\",\"streamlit\",\"resources\",\"pca_mean_image.pkl\")\n",
    "\n",
    "# Exporter les résultats si nécessaire\n",
    "mean_images_df.to_pickle(path_mean_image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RadioPulmonaire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
