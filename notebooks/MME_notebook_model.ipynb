{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `Notebook de Model`\n",
    "\n",
    "Notebook de Mickael MELKOWSKI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Config`\n",
    "\n",
    "### `Import`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pathlib\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "from random import shuffle\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "\n",
    "# check for GPU support\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "# chemin relatif vers le dossier data\n",
    "home = pathlib.Path(\"../\")\n",
    "path_to_data = pathlib.Path(\"../data\")\n",
    "\n",
    "data_folder_path = path_to_data / \"raw\" / \"COVID-19_Radiography_Dataset\"\n",
    "output_path = path_to_data / \"processed\" / \"covid_19_masked_tiny_500\"\n",
    "folder_to_process = [\"Lung_Opacity\",\"COVID\",\"Normal\",\"Viral_Pneumonia\"]\n",
    "\n",
    "# model save path\n",
    "# \"/home/tylio/code/Project_radio_pulmo/code/radio_pulmo/models\"\n",
    "model_save_path = home / \"models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `PyTorch`\n",
    "\n",
    "### `DataLoading`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pathlib\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import numpy as np\n",
    "\n",
    "# config\n",
    "dataset_path = \"/home/tylio/code/Project_radio_pulmo/code/radio_pulmo/data/processed/covid_19_masked_tiny_500\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Normalization`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les transformations (optionnel, mais recommandé)\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((64, 64)),  # Redimensionne les images\n",
    "    transforms.ToTensor(),  # Convertit les images en tenseurs\n",
    "])\n",
    "\n",
    "# Charger les données à partir du dossier\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "#dataset_test = datasets.ImageFolder(root='Testing', transform=transform)\n",
    "\n",
    "# mean and std for normalization\n",
    "def get_mean_std(loader):\n",
    "    # Compute the mean and standard deviation of all pixels in the dataset\n",
    "    num_pixels = 0\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    for images, _ in loader:\n",
    "        batch_size, num_channels, height, width = images.shape\n",
    "        num_pixels += batch_size * height * width\n",
    "        mean += images.mean(axis=(0, 2, 3)).sum()\n",
    "        std += images.std(axis=(0, 2, 3)).sum()\n",
    "\n",
    "    mean /= num_pixels\n",
    "    std /= num_pixels\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "loader = DataLoader(full_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "mean, std = get_mean_std(loader)\n",
    "\n",
    "# Définir les transformations (optionnel, mais recommandé)\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((64, 64)),  # Redimensionne les images\n",
    "    # transforms.RandomRotation(10), # Rotates the images upto Max of 10 Degrees\n",
    "    # transforms.RandomHorizontalFlip(p=0.4), #Performs Horizantal Flip over images \n",
    "    transforms.ToTensor(),  # Convertit les images en tenseurs\n",
    "    transforms.Normalize(mean=mean, std=std)  # normalize\n",
    "])\n",
    "\n",
    "# Re-Charger les données avec la nouvelle transformation\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Normalization and data augmentation`\n",
    "\n",
    "Test en ajoutant aussi un resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les transformations (optionnel, mais recommandé)\n",
    "transform = transforms.Compose([\n",
    "    # transforms.Resize((64, 64)),  # Redimensionne les images\n",
    "    transforms.ToTensor(),  # Convertit les images en tenseurs\n",
    "])\n",
    "\n",
    "# Charger les données à partir du dossier\n",
    "full_dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "#dataset_test = datasets.ImageFolder(root='Testing', transform=transform)\n",
    "\n",
    "# mean and std for normalization\n",
    "def get_mean_std(loader):\n",
    "    # Compute the mean and standard deviation of all pixels in the dataset\n",
    "    num_pixels = 0\n",
    "    mean = 0.0\n",
    "    std = 0.0\n",
    "    for images, _ in loader:\n",
    "        batch_size, num_channels, height, width = images.shape\n",
    "        num_pixels += batch_size * height * width\n",
    "        mean += images.mean(axis=(0, 2, 3)).sum()\n",
    "        std += images.std(axis=(0, 2, 3)).sum()\n",
    "\n",
    "    mean /= num_pixels\n",
    "    std /= num_pixels\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "loader = DataLoader(full_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "mean_nums, std_nums = get_mean_std(loader)\n",
    "\n",
    "# Définir les transformations (optionnel, mais recommandé)\n",
    "data_transforms = {\n",
    "    \"train\":transforms.Compose([\n",
    "        transforms.Resize((150,150)), #Resizes all images into same dimension\n",
    "        transforms.RandomRotation(10), # Rotates the images upto Max of 10 Degrees\n",
    "        transforms.RandomHorizontalFlip(p=0.4), #Performs Horizantal Flip over images \n",
    "        transforms.ToTensor(), # Coverts into Tensors\n",
    "        transforms.Normalize(mean = mean_nums, std=std_nums)]), # Normalizes\n",
    "\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((150,150)),\n",
    "        transforms.CenterCrop(150), #Performs Crop at Center and resizes it to 150x150\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean_nums, std = std_nums)\n",
    "    ])}\n",
    "\n",
    "# Re-Charger les données avec la nouvelle transformation\n",
    "def load_split_train_test(datadir, data_transforms, valid_size = .2):\n",
    "    train_data = datasets.ImageFolder(\n",
    "        datadir,\n",
    "        transform=data_transforms['train']\n",
    "        ) #Picks up Image Paths from its respective folders and label them\n",
    "    test_data = datasets.ImageFolder(\n",
    "        datadir,\n",
    "        transform=data_transforms['val']\n",
    "        )\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    np.random.shuffle(indices)\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "    dataset_size = {\"train\":len(train_idx), \"val\":len(test_idx)}\n",
    "    train_sampler = SubsetRandomSampler(train_idx) # Sampler for splitting train and val images\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    trainloader = torch.utils.data.DataLoader(train_data,\n",
    "                   sampler=train_sampler, batch_size=8) # DataLoader provides data from traininng and validation in batches\n",
    "    testloader = torch.utils.data.DataLoader(test_data,\n",
    "                   sampler=test_sampler, batch_size=8)\n",
    "    return trainloader, testloader, dataset_size\n",
    "\n",
    "dataloader_train, dataloader_test, dataset_size = load_split_train_test(dataset_path, data_transforms, .2)\n",
    "dataloaders = {\"train\":dataloader_train, \"val\":dataloader_test}\n",
    "data_sizes = {x: len(dataloaders[x].sampler) for x in ['train','val']}\n",
    "class_names = dataloader_train.dataset.classes\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Splitting data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset 80%, 20% --> [0.8, 0.2]\n",
    "dataset_train, dataset_test = torch.utils.data.random_split(full_dataset, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloader object\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Baseline Model definition from hugging face`\n",
    "\n",
    "[Hugging face models image classification sort by downloads](https://huggingface.co/models?pipeline_tag=image-classification&sort=downloads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test ResNet-50\n",
    "\n",
    "[ResNet50_hugging_face](https://huggingface.co/microsoft/resnet-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, ResNetForImageClassification\n",
    "# import torchgen\n",
    "\n",
    "model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "# freeze (false) or unfreeze params (True):\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Adaptation to our 4 classes by changing the final layer\n",
    "num_labels = 4\n",
    "model.num_labels = num_labels\n",
    "# model.classifier = torch.nn.Linear(model.classifier.in_features, num_labels)\n",
    "model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, num_labels)\n",
    "\n",
    "device = \"cuda\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test VGG16\n",
    "\n",
    "[vgg16.tv_in1k_hugging_face](https://huggingface.co/timm/vgg16.tv_in1k) --> trained on ImageNet 1k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "model = timm.create_model('vgg16.tv_in1k', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = model.features[-3].out_channels\n",
    "print(model.features[-3])\n",
    "model.head.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model.head.fc) --> Linear(in_features=4096, out_features=1000, bias=True)\n",
    "model.head.fc = torch.nn.Linear(4096, 4)\n",
    "\n",
    "device = \"cuda\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze (false) or unfreeze params (True):\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# Adaptation to our 4 classes by changing the final layer\n",
    "num_labels = 4\n",
    "model.num_labels = num_labels\n",
    "# model.classifier = torch.nn.Linear(model.classifier.in_features, num_labels)\n",
    "# model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, num_labels)\n",
    "\n",
    "#device = \"cuda\"\n",
    "#model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Baseline Model definition`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "device = \"cuda\"\n",
    "model = nn.Sequential(\n",
    "   nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3), # output 16, 254, 254\n",
    "   nn.MaxPool2d(kernel_size=2), # output 16, 127, 127\n",
    "   nn.ReLU(),\n",
    "    \n",
    "   nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3), # 32, 125, 125\n",
    "   nn.ReLU(),\n",
    "   nn.MaxPool2d(kernel_size=2), # output 32, 62, 62\n",
    "    \n",
    "   nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3), # output  64, 60, 60\n",
    "   nn.ReLU(),\n",
    "   nn.MaxPool2d(kernel_size=2), # output 64, 30, 30\n",
    "    \n",
    "   nn.Flatten(),\n",
    "   nn.Linear(64 * 30 * 30, 64), # on précise ici la dim finale --> 64, 30, 30\n",
    "   nn.ReLU(),\n",
    "   nn.Linear(64, 4)\n",
    "\n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Summary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "summary(model, input_size=(3,256,256), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Loss function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_batch, y_batch = next(iter(dataloader_train))\n",
    "\n",
    "# Définir la fonction de perte\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "y_pred = model(X_batch.to(device))\n",
    "\n",
    "criterion(y_pred, y_batch.to(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Fitting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from tqdm.notebook import tqdm\n",
    "epochs = 10\n",
    "\n",
    "# Définition de l'optimizer\n",
    "optimizer = optim.Adam(model.parameters(), 1e-2)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Dans ce mode certaines couches du modèle agissent différemment\n",
    "    model.train()\n",
    "    loss_total = 0\n",
    "    # Barre de progression\n",
    "    progress_bar = tqdm(\n",
    "            dataloader_train, desc=\"Epoch {:1d}\".format(epoch), leave=True, disable=False\n",
    "        )\n",
    "    \n",
    "    for i, batch in enumerate(progress_bar):\n",
    "        # Batch de données\n",
    "        X_batch, y_batch = batch\n",
    "        \n",
    "        # Device\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        # Gradient mis 0\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Calcul de prédiction\n",
    "        y_pred = model(X_batch.to(torch.float32))\n",
    "\n",
    "        # Calcul de la fonction de perte\n",
    "        loss =  criterion(y_pred, y_batch) #torch.mean(torch.abs(y_pred- y_batch.to(torch.float32)))#\n",
    "        # Backpropagation : calculer le gradient de la loss en fonction de chaque couche\n",
    "        loss.backward()\n",
    "        \n",
    "        # Clipper le gradient entre 0 et 1 pour plus de stabilité\n",
    "        #  torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Descente de gradient : actualisation des paramètres\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss_total += loss.item()\n",
    "        \n",
    "        progress_bar.set_postfix(\n",
    "            {\n",
    "                \"training_loss\": \"{:.3f}\".format(loss_total/(i+1))}\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Evaluation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate(dataloader_val):\n",
    "    # Passer le modèle en évaluation\n",
    "    model.eval()\n",
    "    # Calculer la loss totale\n",
    "    loss_val_total = 0\n",
    "    # Stocker les prédictions et les vraies valeurs.\n",
    "    predictions, true_vals = [], []\n",
    "    for batch in dataloader_val:\n",
    "        X_batch, y_batch = batch\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            # Prédiction du modèle pour un batch donné\n",
    "            y_pred = model(X_batch.to(torch.float32))\n",
    "        # Calcul de la fonction de perte pour l'utiliser comme une métrique\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        # Cummuler la fonction de perte de tous les lots de données.\n",
    "        loss_val_total += loss.item()\n",
    "        # Enregistrer les prédictions pour les utiliser plus tard\n",
    "        predictions.extend(y_pred.detach().cpu().numpy())\n",
    "        # Enregistrer les vraies valeurs pour les utiliser plus tard\n",
    "        true_vals.extend(y_batch.cpu().numpy())\n",
    "\n",
    "    # Loss du jeu de données val\n",
    "    loss_val_avg = loss_val_total / len(dataloader_val)\n",
    "    # Ensemble des prédictions du jeu de données\n",
    "    predictions = np.array(predictions)\n",
    "    # Id prediction\n",
    "    predictions = np.argmax(predictions, axis=-1)\n",
    "    # Ensemble des vraies valeurs du jeu de données\n",
    "    true_vals = np.array(true_vals)\n",
    "    return {\"loss\":loss_val_avg, \"accuracy\":accuracy_score(true_vals, predictions)}\n",
    "\n",
    "\n",
    "metrics = evaluate(dataloader_test)\n",
    "\n",
    "print(f\"Loss: {metrics['loss']}\")\n",
    "print(f\"Accuracy : {metrics['accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Confusion matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "on_cuda = True # computed using cuda\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in dataloader_test:\n",
    "    if on_cuda:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    output = model(inputs) # Feed Network\n",
    "\n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    y_pred.extend(output) # Save Prediction\n",
    "\n",
    "    labels = labels.data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "classes = folder_to_process\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(cf_matrix / np.sum(cf_matrix, axis=1)[:, None], \n",
    "                     index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (6,4))\n",
    "sn.heatmap(df_cm, annot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DenseNet-121 architecture`\n",
    "\n",
    "Using tuto on kaggle: [covid-19-detection-pytorch-tutorial](https://www.kaggle.com/code/arunrk7/covid-19-detection-pytorch-tutorial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Model creation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = folder_to_process\n",
    "device=\"cuda\"\n",
    "\n",
    "def CNN_Model(pretrained=True):\n",
    "    model = models.densenet121(weights=pretrained) # Returns Defined Densenet model with weights trained on ImageNet\n",
    "    num_ftrs = model.classifier.in_features # Get the number of features output from CNN layer\n",
    "    model.classifier = nn.Linear(num_ftrs, len(class_names)) # Overwrites the Classifier layer with custom defined layer for transfer learning\n",
    "    model = model.to(device) # Transfer the Model to GPU if available\n",
    "    return model\n",
    "\n",
    "model = CNN_Model(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Every model Training and evaluation`\n",
    "\n",
    "La partie ci-dessous contient le code pour le training et evaluation du model contenue dans la variable `model` avec le dataset d'entrainement de validation dans le dict `dataloaders`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Criterion & Optimizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify loss function (categorical cross-entropy loss)\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# Specify optimizer which performs Gradient Descent\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1) # Learning Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Training function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\"train\":dataloader_train,\n",
    "               \"val\":dataloader_test}\n",
    "data_sizes = {x: len(dataloaders[x].sampler) for x in ['train','val']}\n",
    "\n",
    "metrics = {\n",
    "    \"acc\":[],\n",
    "    \"val_acc\":[],\n",
    "    \"loss\":[],\n",
    "    \"val_loss\":[],\n",
    "}\n",
    "\n",
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, num_epochs=10):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = np.inf\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train() # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            current_loss = 0.0\n",
    "            current_corrects = 0\n",
    "            current_kappa = 0\n",
    "            val_kappa = list()\n",
    "\n",
    "            for inputs, labels in tqdm.tqdm(dataloaders[phase], desc=phase, leave=False):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # We need to zero the gradients in the Cache.\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Time to carry out the forward training poss\n",
    "                # We only need to log the loss stats if we are in training phase\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                if phase == 'train':\n",
    "                    scheduler.step()\n",
    "\n",
    "                # We want variables to hold the loss statistics\n",
    "                current_loss += loss.item() * inputs.size(0)\n",
    "                current_corrects += torch.sum(preds == labels.data)\n",
    "                val_kappa.append(cohen_kappa_score(preds.cpu().numpy(), labels.data.cpu().numpy()))\n",
    "\n",
    "            epoch_loss = current_loss / data_sizes[phase]\n",
    "            epoch_acc = current_corrects.double() / data_sizes[phase]\n",
    "\n",
    "            if phase == 'val':\n",
    "                epoch_kappa = np.mean(val_kappa)\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} | {phase} Accuracy: {epoch_acc:.4f} | Kappa Score: {epoch_kappa:.4f}')\n",
    "                metrics[\"acc\"].append(float(epoch_acc))\n",
    "                metrics[\"loss\"].append(float(epoch_loss))\n",
    "            else:\n",
    "                print(f'{phase} Loss: {epoch_loss:.4f} | {phase} Accuracy: {epoch_acc:.4f}')\n",
    "                metrics[\"val_acc\"].append(float(epoch_acc))\n",
    "                metrics[\"val_loss\"].append(float(epoch_loss))\n",
    "\n",
    "            # EARLY STOPPING\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                print('Val loss Decreased from {:.4f} to {:.4f} \\nSaving Weights... '.format(best_loss, epoch_loss))\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_since = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_since // 60, time_since % 60))\n",
    "    print('Best val loss: {:.4f}'.format(best_loss))\n",
    "\n",
    "    # Now we'll load in the best model weights and return it\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Visual functions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "class_names = folder_to_process\n",
    "\n",
    "#Statistics Based on ImageNet Data for Normalisation\n",
    "mean_nums = [mean, mean, mean]\n",
    "std_nums = [std, std, std]\n",
    "\n",
    "def imshow(inp, size =(30,30), title=None, normalized=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalized:\n",
    "        mean = mean_nums\n",
    "        std = std_nums\n",
    "        inp = std * inp + mean\n",
    "        inp = np.clip(inp, 0, 1)\n",
    "\n",
    "    plt.figure(figsize=size)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title, size=30)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_handeled = 0\n",
    "    ax = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_handeled += 1    \n",
    "                ax = plt.subplot(num_images//2, 2, images_handeled)\n",
    "                ax.axis('off')\n",
    "                ax.set_title('Actual: {} predicted: {}'.format(class_names[labels[j].item()],class_names[preds[j]]))\n",
    "                imshow(inputs.cpu().data[j], (5,5))\n",
    "\n",
    "                if images_handeled == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epochs = 10\n",
    "base_model = train_model(model, criterion, optimizer, exp_lr_scheduler, dataloaders, num_epochs=nb_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Saving`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), model_save_path / \"pytorch/dense121_normalized.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Loading`\n",
    "\n",
    "See: [PyTorch saving_loading_models](https://pytorch.org/tutorials/beginner/saving_loading_models.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN_Model(pretrained=True)\n",
    "model.load_state_dict(torch.load(model_save_path / \"pytorch/dense121_normalized.pt\", weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Eval and visualisation`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_model(base_model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Accuracy and loss`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use metrics dict from train function\n",
    "\n",
    "nb_epochs = 10\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "# Courbe du score de test du réseau Dense 121\n",
    "plt.plot(np.arange(1 , nb_epochs + 1, 1),\n",
    "         metrics[\"acc\"], \n",
    "         label = 'acc Dense121',\n",
    "         color = 'blue')\n",
    "plt.plot(np.arange(1 , nb_epochs + 1, 1),\n",
    "         metrics[\"val_acc\"],\n",
    "         label = 'val_acc Dense121',\n",
    "         color = 'red')\n",
    "# Labels des axes\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "# Affichage de la légende\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "# Courbe du score de test du réseau Dense 121\n",
    "plt.plot(np.arange(1 , nb_epochs + 1, 1),\n",
    "         metrics[\"loss\"], \n",
    "         label = 'loss Dense121',\n",
    "         color = 'blue')\n",
    "plt.plot(np.arange(1 , nb_epochs + 1, 1),\n",
    "         metrics[\"val_loss\"],\n",
    "         label = 'val_loss Dense121',\n",
    "         color = 'red')\n",
    "\n",
    "# Labels des axes\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "# Affichage de la légende\n",
    "plt.legend()\n",
    "# Affichage de la figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Confusion Matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "\n",
    "on_cuda = True # computed using cuda\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "# iterate over test data\n",
    "for inputs, labels in dataloader_test:\n",
    "    if on_cuda:\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "    output = model(inputs) # Feed Network\n",
    "\n",
    "    output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "    y_pred.extend(output) # Save Prediction\n",
    "\n",
    "    labels = labels.data.cpu().numpy()\n",
    "    y_true.extend(labels) # Save Truth\n",
    "\n",
    "# constant for classes\n",
    "classes = folder_to_process\n",
    "\n",
    "# Build confusion matrix\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "df_cm = pd.DataFrame(100*cf_matrix / np.sum(cf_matrix, axis=1)[:, None], \n",
    "                     index = [i for i in classes],\n",
    "                     columns = [i for i in classes])\n",
    "plt.figure(figsize = (6,4))\n",
    "sn.heatmap(df_cm, annot=True)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('DenseNet121 Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Hugging Face model Training and evaluation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data for hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the dataset\n",
    "#dataset_path = \"/home/processed/covid_19_masked_tiny_500\"\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=dataset_path)\n",
    "\n",
    "# Initialize the processor for resizing and normalization\n",
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "# Define a preprocessing function\n",
    "def preprocess(batch):\n",
    "    # Process each image in the batch\n",
    "    images = []\n",
    "    for image in batch[\"image\"]:\n",
    "        # Convert image to RGB if it's grayscale\n",
    "        if image.mode != \"RGB\":\n",
    "            image = image.convert(\"RGB\")\n",
    "        images.append(image)\n",
    "        \n",
    "    # Process images with the processor to resize and normalize\n",
    "    batch[\"pixel_values\"] = processor(images=images, size=256)[\"pixel_values\"]\n",
    "    return batch\n",
    "\n",
    "# Apply preprocessing to the dataset\n",
    "dataset = dataset.map(preprocess, batched=True)\n",
    "\n",
    "# Verif\n",
    "# print(dataset_train[0][\"image\"])\n",
    "\n",
    "# Splitting the dataset into 80% train and 20% test\n",
    "split_dataset = dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "\n",
    "# Access the train and test splits\n",
    "dataset_train = split_dataset[\"train\"]\n",
    "dataset_test = split_dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training hyperparameters\n",
    "\n",
    "Using [transformers/training tutorial](https://huggingface.co/docs/transformers/training)\n",
    "\n",
    "Create a [TrainingArguments](https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.TrainingArguments) class which contains all the hyperparameters you can tune as well as flags for activating different training options.\n",
    "\n",
    "With 'eval_strategy' parameter in your training arguments to report the evaluation metric at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    )\n",
    "\n",
    "backup_params = \"\"\"\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate\n",
    "\n",
    "[Trainer](https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer) does not automatically evaluate model performance during training. You’ll need to pass Trainer a function to compute and report metrics. The [🤗 Evaluate](https://huggingface.co/docs/evaluate/index) library provides a simple [accuracy](https://huggingface.co/spaces/evaluate-metric/accuracy) function you can load with the evaluate.load (see this [quicktour](https://huggingface.co/docs/evaluate/a_quick_tour) for more information) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer object\n",
    "\n",
    "Create a [Trainer](https://huggingface.co/docs/transformers/v4.46.0/en/main_classes/trainer#transformers.Trainer) object with your model, training arguments, training and test datasets, and evaluation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_train,\n",
    "    eval_dataset=dataset_test,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recup max prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Step 1: Get predictions\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Step 2: Compute confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=dataset_test.features[\"label\"].names)\n",
    "\n",
    "# Step 3: Plot confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "disp.plot(ax=ax, cmap=\"Blues\", values_format=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
